{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T11:23:05.333045Z",
     "iopub.status.busy": "2023-12-04T11:23:05.332774Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0342c266f7847158dc96d4e6ec49694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    }
   ],
   "source": [
    "// import org.apache.spark.sql.functions._\n",
    "// import org.apache.spark.sql.{SparkSession, functions, DataFrame}\n",
    "// import org.apache.spark.sql.types.{StructType, StructField, StringType, ArrayType}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.hadoop.fs.{FileSystem,Path}\n",
    "import java.net.{URI,URL}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val spark = SparkSession.builder.appName(\"readDir\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val path = \"s3://emr-data-sync/segment-logs/\"\n",
    "val conf = spark.sparkContext.hadoopConfiguration\n",
    "val fs = FileSystem.get(new URI(path), conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "// val dirs = fs.listStatus(new Path(path)).filter(_.isDirectory).map(_.getPath.toString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getDirs(path: String) = fs.listStatus(new Path(path)).filter(_.isDirectory).map(_.getPath.toString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "// for ( path <- getDirs(path) ) {\n",
    "//     val directories = path.split(\"/\").last\n",
    "//     getDirs(path).foreach { dir =>\n",
    "//         val last = dir.split(\"/\").last\n",
    "//         println(last)\n",
    "//     }\n",
    "// }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val result = for {\n",
    "  path <- getDirs(path)\n",
    "  dir <- getDirs(path)\n",
    "} yield dir.split(\"/\").last\n",
    "\n",
    "result.foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark",
   "language": "scala",
   "name": "sparkkernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
